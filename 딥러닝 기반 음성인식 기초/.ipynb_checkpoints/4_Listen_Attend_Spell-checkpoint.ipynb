{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6iN54BqnSTpk"
   },
   "source": [
    "\n",
    "### Reference \n",
    "\n",
    "- Digital Signal Processing Lecture\u000b",
    "https://github.com/spatialaudio/digital-signal-processing-lecture \n",
    "\n",
    "- Python for Signal Processing (unipingco)\u000b",
    "https://github.com/unpingco/Python-for-Signal-Processing \n",
    "\n",
    "- Audio for Deep Learning (남기현님)\u000b",
    "https://tykimos.github.io/2019/07/04/ISS_2nd_Deep_Learning_Conference_All_Together/ \n",
    "\n",
    "- 오디오 전처리 작업을 위한 연습 (박수철님)\u000b",
    "https://github.com/scpark20/audio-preprocessing-practice \n",
    "\n",
    "- Musical Applications of Machine Learning\u000b",
    "https://mac.kaist.ac.kr/~juhan/gct634/ \n",
    "\n",
    "- Awesome audio study materials for Korean (최근우님)\u000b",
    "https://github.com/keunwoochoi/awesome-audio-study-materials-for-korean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4hfYNb2wu9m"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114,
     "referenced_widgets": [
      "5acbd787bf724b298c2d289744ef66fd",
      "a2f2f506ed9045a2864978e81df4062e",
      "191b17a34c394310b00c989ff0690b53",
      "76708ab4783d4882b5c33ba6d135a4a9",
      "cc2f39e4e5574207bb8285edead9c592",
      "c83f4f53ebd443ed965ed438b27d34b0",
      "92c7bb2f44d44e1bb3f9c9fc45054a8f",
      "32ab6de4c1e04e258b20545704b7264f",
      "29215b7037b3458188b8809282fd72df",
      "2689d7f2a46146f09976aeaaa2ea9a95",
      "0f0171610d604eb0b5b92194d502eda2",
      "95430f18cd6348b7a448bfcfc0d9812b",
      "b6dc3c88cdc64697a94d18689f3abfa4",
      "597039f064d84288a812954117494cfa",
      "e476fc39f93d45bab331e59310dfc890",
      "4a5f508fd1434f57b93641a33df6c704"
     ]
    },
    "colab_type": "code",
    "id": "Bb06mH8jxGtr",
    "outputId": "c4a5849c-d25d-4e9b-9cab-a2a988472771"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acbd787bf724b298c2d289744ef66fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6387309499.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29215b7037b3458188b8809282fd72df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=346663984.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchaudio.datasets.LIBRISPEECH(\"./\", url=\"train-clean-100\", download=True) \n",
    "test_dataset = torchaudio.datasets.LIBRISPEECH(\"./\", url=\"test-clean\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "N8JvgqogxgtA",
    "outputId": "4191e052-48f7-4797-a26e-932c4a0bccf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0007, 0.0008, 0.0007,  ..., 0.0015, 0.0010, 0.0015]]),\n",
       " 16000,\n",
       " 'AT THE INCEPTION OF PLURAL MARRIAGE AMONG THE LATTER DAY SAINTS THERE WAS NO LAW NATIONAL OR STATE AGAINST ITS PRACTISE',\n",
       " 4077,\n",
       " 13754,\n",
       " 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[1]\n",
    "#소리 데이터, 샘플레이트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wlBQJ2QopRFk"
   },
   "outputs": [],
   "source": [
    "def avg_wer(wer_scores, combined_ref_len):\n",
    "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
    "\n",
    "\n",
    "def _levenshtein_distance(ref, hyp):\n",
    "    \"\"\"\"Levenshtein distance\"는 두 시퀀스 간의 차이를 측정하기위한 문자열 메트릭입니다. \n",
    "    \"Levenshtein distanc\"는 한 단어를 다른 단어로 변경하는 데 필요한 최소 한 문자 편집 (대체, 삽입 또는 삭제) 수로 정의됩니다. \n",
    "    \"\"\"\n",
    "    m = len(ref)\n",
    "    n = len(hyp)\n",
    "\n",
    "    # special case\n",
    "    if ref == hyp:\n",
    "        return 0\n",
    "    if m == 0:\n",
    "        return n\n",
    "    if n == 0:\n",
    "        return m\n",
    "\n",
    "    if m < n:\n",
    "        ref, hyp = hyp, ref\n",
    "        m, n = n, m\n",
    "\n",
    "    # use O(min(m, n)) space\n",
    "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
    "\n",
    "    # initialize distance matrix\n",
    "    for j in range(0,n + 1):\n",
    "        distance[0][j] = j\n",
    "\n",
    "    # calculate levenshtein distance\n",
    "    for i in range(1, m + 1):\n",
    "        prev_row_idx = (i - 1) % 2\n",
    "        cur_row_idx = i % 2\n",
    "        distance[cur_row_idx][0] = i\n",
    "        for j in range(1, n + 1):\n",
    "            if ref[i - 1] == hyp[j - 1]:\n",
    "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
    "            else:\n",
    "                s_num = distance[prev_row_idx][j - 1] + 1\n",
    "                i_num = distance[cur_row_idx][j - 1] + 1\n",
    "                d_num = distance[prev_row_idx][j] + 1\n",
    "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
    "\n",
    "    return distance[m % 2][n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ru55tshPqejt"
   },
   "outputs": [],
   "source": [
    "\n",
    "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
    "    \"\"\"참조 시퀀스와 가설 시퀀스 사이의 거리를 단어 수준으로 계산합니다.\n",
    "     : param reference : 참조 문장.\n",
    "     : param hypothesis : 가설 문장.\n",
    "     : param ignore_case : 대소 문자 구분 여부.\n",
    "     : param delimiter : 입력 문장의 구분자.\n",
    "    \"\"\"\n",
    "    if ignore_case == True:\n",
    "        reference = reference.lower()\n",
    "        hypothesis = hypothesis.lower()\n",
    "\n",
    "    ref_words = reference.split(delimiter)\n",
    "    hyp_words = hypothesis.split(delimiter)\n",
    "\n",
    "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
    "    return float(edit_distance), len(ref_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-LCRpXVqhv8"
   },
   "outputs": [],
   "source": [
    "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
    "    if ignore_case == True:\n",
    "        reference = reference.lower()\n",
    "        hypothesis = hypothesis.lower()\n",
    "\n",
    "    join_char = ' '\n",
    "    if remove_space == True:\n",
    "        join_char = ''\n",
    "\n",
    "    reference = join_char.join(filter(None, reference.split(' ')))\n",
    "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
    "\n",
    "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
    "    return float(edit_distance), len(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9gBZ_3-Sqm5D"
   },
   "outputs": [],
   "source": [
    "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
    "    \"\"\"Calculate word error rate (WER). \n",
    "    WER = (Sw + Dw + Iw) / Nw\n",
    "    Sw는 대체 된 단어의 수입니다.\n",
    "    Dw는 삭제 된 단어의 수입니다.\n",
    "    Iw는 삽입 된 단어의 수입니다.\n",
    "    Nw는 참조의 단어 수입니다.\n",
    "    \"\"\"\n",
    "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
    "                                         delimiter)\n",
    "    if ref_len == 0:\n",
    "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
    "\n",
    "    wer = float(edit_distance) / ref_len\n",
    "    return wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F6YUEk-2qqaw"
   },
   "outputs": [],
   "source": [
    "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
    "    \"\"\"Calculate charactor error rate (CER). \n",
    "        CER = (Sc + Dc + Ic) / Nc\n",
    "        Sc is the number of characters substituted,\n",
    "        Dc is the number of characters deleted,\n",
    "        Ic is the number of characters inserted\n",
    "        Nc is the number of characters in the reference\n",
    "    \"\"\"\n",
    "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
    "                                         remove_space)\n",
    "\n",
    "    if ref_len == 0:\n",
    "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
    "\n",
    "    cer = float(edit_distance) / ref_len\n",
    "    return cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cS2jhIrBqs_G"
   },
   "outputs": [],
   "source": [
    "class TextTransform:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "    def __init__(self):\n",
    "        char_map_str = \"\"\"\n",
    "        ' 0\n",
    "        <SPACE> 1\n",
    "        a 2\n",
    "        b 3\n",
    "        c 4\n",
    "        d 5\n",
    "        e 6\n",
    "        f 7\n",
    "        g 8\n",
    "        h 9\n",
    "        i 10\n",
    "        j 11\n",
    "        k 12\n",
    "        l 13\n",
    "        m 14\n",
    "        n 15\n",
    "        o 16\n",
    "        p 17\n",
    "        q 18\n",
    "        r 19\n",
    "        s 20\n",
    "        t 21\n",
    "        u 22\n",
    "        v 23\n",
    "        w 24\n",
    "        x 25\n",
    "        y 26\n",
    "        z 27\n",
    "        \"\"\"\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch, index = line.split()\n",
    "            self.char_map[ch] = int(index)\n",
    "            self.index_map[int(index)] = ch\n",
    "        self.index_map[1] = ' '\n",
    "\n",
    "    def text_to_int(self, text):\n",
    "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text:\n",
    "            if c == ' ':\n",
    "                ch = self.char_map['<SPACE>']\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def int_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string).replace('<SPACE>', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HMUWPlL8qwQg"
   },
   "outputs": [],
   "source": [
    "train_audio_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
    ")\n",
    "\n",
    "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
    "\n",
    "text_transform = TextTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrbecqsFq8qM"
   },
   "outputs": [],
   "source": [
    "def data_processing(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for (waveform, _, utterance, _, _, _) in data:\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        elif data_type == 'valid':\n",
    "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            raise Exception('data_type should be train or valid')\n",
    "        spectrograms.append(spec)\n",
    "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0]//2)\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXAYnQ4arD2P"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1,\n",
    "                 input_dropout_p=0, dropout_p=0,\n",
    "                 bidirectional=False, rnn_cell='gru', variable_lengths=False):\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.variable_lengths = variable_lengths\n",
    "\n",
    "        if rnn_cell.lower() == 'lstm':\n",
    "            self.rnn_cell = nn.LSTM\n",
    "        elif rnn_cell.lower() == 'gru':\n",
    "            self.rnn_cell = nn.GRU\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported RNN Cell: {0}\".format(rnn_cell))\n",
    "\n",
    "        \"\"\"\n",
    "        Copied from https://github.com/SeanNaren/deepspeech.pytorch/blob/master/model.py\n",
    "        Copyright (c) 2017 Sean Naren\n",
    "        MIT License\n",
    "        \"\"\"\n",
    "        outputs_channel = 32\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, outputs_channel, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5)),\n",
    "            nn.BatchNorm2d(outputs_channel),\n",
    "            nn.Hardtanh(0, 20, inplace=True),\n",
    "            nn.Conv2d(outputs_channel, outputs_channel, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5)),\n",
    "            nn.BatchNorm2d(outputs_channel),\n",
    "            nn.Hardtanh(0, 20, inplace=True)\n",
    "        )\n",
    "\n",
    "        rnn_input_dims = int(math.floor(input_size + 2 * 20 - 41) / 2 + 1)\n",
    "        rnn_input_dims = int(math.floor(rnn_input_dims + 2 * 10 - 21) / 2 + 1)\n",
    "        rnn_input_dims *= outputs_channel\n",
    "        \n",
    "        self.rnn =  self.rnn_cell(rnn_input_dims, self.hidden_size, self.n_layers, dropout=self.dropout_p, bidirectional=self.bidirectional)\n",
    "\n",
    "\n",
    "    def forward(self, input_var, input_lengths=None):\n",
    "        \"\"\"\n",
    "        param:input_var: Encoder inputs, Spectrogram, Shape=(B,1,D,T)\n",
    "        param:input_lengths: inputs sequence length without zero-pad\n",
    "        \"\"\"\n",
    "        output_lengths = self.get_seq_lens(input_lengths)\n",
    "\n",
    "        x = input_var # (B,1,D,T)\n",
    "        x, _ = self.conv(x, output_lengths) # (B, C, D, T)\n",
    "        \n",
    "        x_size = x.size()\n",
    "        x = x.view(x_size[0], x_size[1] * x_size[2], x_size[3]) # (B, C * D, T)\n",
    "        x = x.transpose(1, 2).transpose(0, 1).contiguous() # (T, B, D)\n",
    "\n",
    "        x = nn.utils.rnn.pack_padded_sequence(x, output_lengths)\n",
    "        x, h_state = self.rnn(x)\n",
    "        x, _ = nn.utils.rnn.pad_packed_sequence(x)\n",
    "        x = x.transpose(0, 1) # (B, T, D)\n",
    "        return x, h_state\n",
    "\n",
    "\n",
    "    def get_seq_lens(self, input_length):\n",
    "        seq_len = input_length\n",
    "        for m in self.conv.modules():\n",
    "            if type(m) == nn.modules.conv.Conv2d :\n",
    "                seq_len = ((seq_len + 2 * m.padding[1] - m.dilation[1] * (m.kernel_size[1] - 1) - 1) / m.stride[1] + 1)\n",
    "\n",
    "        return seq_len.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMITaH3ALmr8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dec_dim, enc_dim, conv_dim, attn_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.dec_dim = dec_dim\n",
    "        self.enc_dim = enc_dim\n",
    "        self.conv_dim = conv_dim\n",
    "        self.attn_dim = attn_dim\n",
    "        self.conv = nn.Conv1d(in_channels=1, out_channels=self.attn_dim, kernel_size=3, padding=1)\n",
    "\n",
    "        self.W = nn.Linear(self.dec_dim, self.attn_dim, bias=False)\n",
    "        self.V = nn.Linear(self.enc_dim, self.attn_dim, bias=False)\n",
    "\n",
    "        self.fc = nn.Linear(attn_dim, 1, bias=True)\n",
    "        self.b = nn.Parameter(torch.rand(attn_dim))\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, queries, values, last_attn):\n",
    "        \"\"\"\n",
    "        param:quries: Decoder hidden states, Shape=(B,1,dec_D)\n",
    "        param:values: Encoder outputs, Shape=(B,enc_T,enc_D)\n",
    "        param:last_attn: Attention weight of previous step, Shape=(batch, enc_T)\n",
    "        \"\"\"\n",
    "        batch_size = queries.size(0)\n",
    "        dec_feat_dim = queries.size(2)\n",
    "        enc_feat_len = values.size(1)\n",
    "\n",
    "        # conv_attn = (B, enc_T, conv_D)\n",
    "        conv_attn = torch.transpose(self.conv(last_attn.unsqueeze(dim=1)), 1, 2)\n",
    "\n",
    "        # (B, enc_T)\n",
    "        score =  self.fc(self.tanh(\n",
    "         self.W(queries) + self.V(values) + conv_attn + self.b\n",
    "        )).squeeze(dim=-1)\n",
    "\n",
    "        attn_weight = self.softmax(score) \n",
    "        # (B, 1, enc_T) * (B, enc_T, enc_D) -> (B, 1, enc_D) \n",
    "        context = torch.bmm(attn_weight.unsqueeze(dim=1), values)\n",
    "        return context, attn_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C0wPUMERrnjX"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, hidden_size, encoder_size,\n",
    "                 sos_id, eos_id,\n",
    "                 n_layers=1, rnn_cell='gru', \n",
    "                 bidirectional_encoder=False, bidirectional_decoder=False,\n",
    "                 dropout_p=0, use_attention=True):\n",
    "\n",
    "        self.output_size = vocab_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional_encoder = bidirectional_encoder\n",
    "        self.bidirectional_decoder = bidirectional_decoder\n",
    "        self.encoder_output_size = encoder_size * 2 if self.bidirectional_encoder else encoder_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_len\n",
    "        self.use_attention = use_attention\n",
    "        self.eos_id = eos_id\n",
    "        self.sos_id = sos_id\n",
    "        \n",
    "        if rnn_cell.lower() == 'lstm':\n",
    "            self.rnn_cell = nn.LSTM\n",
    "        elif rnn_cell.lower() == 'gru':\n",
    "            self.rnn_cell = nn.GRU\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported RNN Cell: {0}\".format(rnn_cell))\n",
    "\n",
    "        self.init_input = None\n",
    "        self.rnn = self.rnn_cell(self.hidden_size + self.encoder_output_size, self.hidden_size, self.n_layers,\n",
    "                                 batch_first=True, dropout=dropout_p, bidirectional=self.bidirectional_decoder)\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.hidden_size)\n",
    "        self.attention = Attention(dec_dim=self.hidden_size, enc_dim=self.encoder_output_size, conv_dim=1, attn_dim=self.hidden_size)\n",
    "        self.fc = nn.Linear(self.hidden_size + self.encoder_output_size, self.output_size)\n",
    "\n",
    "    def forward_step(self, input_var, hidden, encoder_outputs, context, attn_w, function):\n",
    "        if self.training:\n",
    "            self.rnn.flatten_parameters()\n",
    "\n",
    "        batch_size = input_var.size(0)\n",
    "        dec_len = input_var.size(1)\n",
    "        enc_len = encoder_outputs.size(1)\n",
    "        enc_dim = encoder_outputs.size(2)\n",
    "        embedded = self.embedding(input_var) # (B, dec_T, voc_D) -> (B, dec_T, dec_D)\n",
    "        embedded = self.input_dropout(embedded)\n",
    "\n",
    "        y_all = []\n",
    "        attn_w_all = []\n",
    "        for i in range(embedded.size(1)):\n",
    "            embedded_inputs = embedded[:, i, :] # (B, dec_D)\n",
    "            \n",
    "            rnn_input = torch.cat([embedded_inputs, context], dim=1) # (B, dec_D + enc_D)\n",
    "            rnn_input = rnn_input.unsqueeze(1) \n",
    "            output, hidden = self.rnn(rnn_input, hidden) # (B, 1, dec_D)\n",
    "\n",
    "            context, attn_w = self.attention(output, encoder_outputs, attn_w) # (B, 1, enc_D), (B, enc_T)\n",
    "            attn_w_all.append(attn_w)\n",
    "            \n",
    "            context = context.squeeze(1)\n",
    "            output = output.squeeze(1) # (B, 1, dec_D) -> (B, dec_D)\n",
    "            context = self.input_dropout(context)\n",
    "            output = self.input_dropout(output)\n",
    "            output = torch.cat((output, context), dim=1) # (B, dec_D + enc_D)\n",
    "\n",
    "            pred = function(self.fc(output), dim=-1)\n",
    "            y_all.append(pred)\n",
    "\n",
    "        return y_all, hidden, context, attn_w_all\n",
    "\n",
    "\n",
    "    def forward(self, inputs=None, encoder_hidden=None, encoder_outputs=None,\n",
    "                    function=F.log_softmax):\n",
    "        \"\"\"\n",
    "        param:inputs: Decoder inputs sequence, Shape=(B, dec_T)\n",
    "        param:encoder_hidden: Encoder last hidden states, Default : None\n",
    "        param:encoder_outputs: Encoder outputs, Shape=(B,enc_T,enc_D)\n",
    "        \"\"\"\n",
    "    \n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        inputs = torch.LongTensor([self.sos_id] * batch_size).view(batch_size, 1)\n",
    "        max_length = self.max_length\n",
    "\n",
    "        decoder_hidden = None\n",
    "        context = encoder_outputs.new_zeros(batch_size, encoder_outputs.size(2)) # (B, D)\n",
    "        attn_w = encoder_outputs.new_zeros(batch_size, encoder_outputs.size(1)) # (B, T)\n",
    "\n",
    "        decoder_outputs = []\n",
    "        sequence_symbols = []\n",
    "        lengths = np.array([max_length] * batch_size)\n",
    "\n",
    "        def decode(step, step_output):\n",
    "            decoder_outputs.append(step_output)\n",
    "            symbols = decoder_outputs[-1].topk(1)[1]\n",
    "            sequence_symbols.append(symbols)\n",
    "            eos_batches = symbols.data.eq(self.eos_id)\n",
    "            if eos_batches.dim() > 0:\n",
    "                eos_batches = eos_batches.cpu().view(-1).numpy()\n",
    "                update_idx = ((lengths > step) & eos_batches) != 0\n",
    "                lengths[update_idx] = len(sequence_symbols)\n",
    "            return symbols\n",
    "\n",
    "        decoder_input = inputs[:, 0].unsqueeze(1)\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, context, attn_w = self.forward_step(decoder_input, \n",
    "                                                                                decoder_hidden,\n",
    "                                                                                encoder_outputs,\n",
    "                                                                                context,\n",
    "                                                                                attn_w,\n",
    "                                                                                function=function)\n",
    "            step_output = decoder_output.squeeze(1)\n",
    "            symbols = decode(di, step_output)\n",
    "            decoder_input = symbols\n",
    "\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gyojINGV98zz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4. Listen Attend Spell",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0f0171610d604eb0b5b92194d502eda2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_597039f064d84288a812954117494cfa",
      "max": 346663984,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b6dc3c88cdc64697a94d18689f3abfa4",
      "value": 346663984
     }
    },
    "191b17a34c394310b00c989ff0690b53": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c83f4f53ebd443ed965ed438b27d34b0",
      "max": 6387309499,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cc2f39e4e5574207bb8285edead9c592",
      "value": 6387309499
     }
    },
    "2689d7f2a46146f09976aeaaa2ea9a95": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29215b7037b3458188b8809282fd72df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0f0171610d604eb0b5b92194d502eda2",
       "IPY_MODEL_95430f18cd6348b7a448bfcfc0d9812b"
      ],
      "layout": "IPY_MODEL_2689d7f2a46146f09976aeaaa2ea9a95"
     }
    },
    "32ab6de4c1e04e258b20545704b7264f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a5f508fd1434f57b93641a33df6c704": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "597039f064d84288a812954117494cfa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5acbd787bf724b298c2d289744ef66fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_191b17a34c394310b00c989ff0690b53",
       "IPY_MODEL_76708ab4783d4882b5c33ba6d135a4a9"
      ],
      "layout": "IPY_MODEL_a2f2f506ed9045a2864978e81df4062e"
     }
    },
    "76708ab4783d4882b5c33ba6d135a4a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32ab6de4c1e04e258b20545704b7264f",
      "placeholder": "​",
      "style": "IPY_MODEL_92c7bb2f44d44e1bb3f9c9fc45054a8f",
      "value": " 5.95G/5.95G [04:06&lt;00:00, 26.0MB/s]"
     }
    },
    "92c7bb2f44d44e1bb3f9c9fc45054a8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "95430f18cd6348b7a448bfcfc0d9812b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a5f508fd1434f57b93641a33df6c704",
      "placeholder": "​",
      "style": "IPY_MODEL_e476fc39f93d45bab331e59310dfc890",
      "value": " 331M/331M [00:13&lt;00:00, 26.1MB/s]"
     }
    },
    "a2f2f506ed9045a2864978e81df4062e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6dc3c88cdc64697a94d18689f3abfa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c83f4f53ebd443ed965ed438b27d34b0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc2f39e4e5574207bb8285edead9c592": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e476fc39f93d45bab331e59310dfc890": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
